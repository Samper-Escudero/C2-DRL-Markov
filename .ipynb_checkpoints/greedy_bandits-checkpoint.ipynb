{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is based on \"Deep Reinforcement Learning in Action\" Manning book by Alex Zai and Brandom Browm. There we are going to create an algorithm to solve multi-armed bandits.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we have to define the function for interacting with the environment.\n",
    "\n",
    "# The expected reward at play k for action a is the arithmetic mean of\n",
    "# all the previous rewards we've received for taking action\n",
    "\n",
    "def expected_reward(action, history):\n",
    "    exp_reward = sum(history[action])/ len(history[action])\n",
    "    return exp_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are different policies to interact with the environment. In this first example, we use an \n",
    "# epsilon greedy policy\n",
    "\n",
    "def get_best_action(actions, history):\n",
    "    exp_rewards = {key:expected_reward(key,history) for key,vals in history.items()}\n",
    "    return max(exp_rewards, key = exp_rewards.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp reward from action 1:  8.0\n",
      "Exp reward from action 2:  4.0\n",
      "Exp reward from action 3:  5.5\n",
      "Best performing action: action 1\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate this functions\n",
    "\n",
    "# define a history of plays\n",
    "history = {1:[5, 9, 10], 2:[4], 3:[4, 7]}\n",
    "\n",
    "# let's calculate the expected reward, which should be the avg value of the accum rewards of this action\n",
    "print(\"Exp reward from action 1: \", expected_reward(1, history)) # (5 + 9 + 10) / 3 = 8\n",
    "print(\"Exp reward from action 2: \", expected_reward(2, history)) # 4\n",
    "print(\"Exp reward from action 3: \", expected_reward(3,history)) # (4 + 7) / 2 = 5.5\n",
    "\n",
    "# best action should be 1\n",
    "print(\"Best performing action: action\",get_best_action(range(1,4), history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bandits, setting exploration ratio to 10%\n",
    "n = 10\n",
    "bandits = np.random.rand(n) #hidden probs associated with each arm\n",
    "eps = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate single rewards based on a probability.\n",
    "def reward(prob, max_reward =10):\n",
    "    # Initial reward set to 0\n",
    "    reward = 0\n",
    "    # Iterate as much times as max_reward\n",
    "    for i in range(max_reward):\n",
    "        # if a random number is higher than prob distribution\n",
    "        if random.random() < prob:\n",
    "            # Increase reward in one \n",
    "            reward += 1\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test reward f(x):  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Test reward f(x): \", reward(0.6, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test reward f(x):  6\n"
     ]
    }
   ],
   "source": [
    "print(\"Test reward f(x): \", reward(0.6, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test reward f(x):  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Test reward f(x): \", reward(0.6, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Avg Reward')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create graph to draw online\n",
    "plt.xlabel(\"Plays\")\n",
    "plt.ylabel(\"Avg Reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_best_arm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2b62dcece06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_arm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpastRewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_best_arm' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    if random.random() > eps:\n",
    "        choice = get_best_arm(pastRewards, actions)\n",
    "    else:\n",
    "        choice = np.where(arms == np.random.choice(arms))[0][0]\n",
    "    thisAV = np.array([[choice, reward(arms[choice])]])\n",
    "    av = np.vstack((av, thisAV))    \n",
    "    percCorrect = 100*(len(av[np.where(av[:,0] == np.argmax(arms))])/len(av))\n",
    "    runningMean = np.mean(av[:,1])\n",
    "    plt.scatter(i, runningMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
