{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition of a Neural Network\n",
    "\n",
    "\n",
    "In the previous notebook, we have seen that we need to keep a tracking of \n",
    "the avg while weighing probabilities and expected rewards. A neural network \n",
    "can, therefore, be a valuable asset in RL as they standout in dataset \n",
    "characterization and learning a model / feature set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandit class copied from Deep Reinforcement Learning in Action book\"\n",
    "\n",
    "class ContextBandit:\n",
    "    def __init__(self, arms=10):\n",
    "        self.arms = arms\n",
    "        self.init_distribution(arms)\n",
    "        self.update_state()\n",
    "        \n",
    "    def init_distribution(self, arms):\n",
    "        # Num states = Num Arms to keep things simple\n",
    "        self.bandit_matrix = np.random.rand(arms,arms)\n",
    "        #each row represents a state, each column an arm\n",
    "        \n",
    "    def reward(self, prob):\n",
    "        reward = 0\n",
    "        for i in range(self.arms):\n",
    "            if random.random() < prob:\n",
    "                reward += 1\n",
    "        return reward\n",
    "        \n",
    "    def get_state(self):\n",
    "        return self.state\n",
    "    \n",
    "    def update_state(self):\n",
    "        self.state = np.random.randint(0,self.arms)\n",
    "        \n",
    "    def get_reward(self,arm):\n",
    "        return self.reward(self.bandit_matrix[self.get_state()][arm])\n",
    "        \n",
    "    def choose_arm(self, arm):\n",
    "        reward = self.get_reward(arm)\n",
    "        self.update_state()\n",
    "        return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_fn(av, tau = 1.12):\n",
    "# This function receives average rewards and outputs the softmax probabilities \n",
    "# Arguments:\n",
    "#   - av: expected averages\n",
    "#   - tau: temperature. High val exaggerates differences; low value promotes homogenity\n",
    "# Output:\n",
    "#   - Softmaxed values\n",
    "\n",
    "    softm = np.exp(av / tau) / np.sum( np.exp(av[:] / tau) )\n",
    "    return softm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Set params \n",
    "\n",
    "bandits = 10\n",
    "env = ContextBandit(bandits)\n",
    "n_in = bandits\n",
    "n_hidden = 100\n",
    "n_out = bandits\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model definition \n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(n_in, n_hidden)),\n",
    "    ('ReLu1', nn.ReLU(inplace = True)),\n",
    "    ('fc2', nn.Linear(n_hidden, n_out)),\n",
    "])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss metric and optimization criterion for training\n",
    "loss = nn.MSELoss(size_average=False)\n",
    "criterion = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
